>   参考：
>
>   -   [Cardelli L. Type systems](https://lucacardelli.name/papers/typesystems.pdf)

# 1 概述

## 类型系统的意义与目标

**类型系统**（Type system）的根本目的是防止程序在运行时出现**执行错误**（Execution error），如非法指令故障或非法内存引用故障。这种保证要求对错误进行精确定义，并证明整个语言在所有可能的运行中都不出现执行错误时，称该语言是**类型健全的**（Type sound）。

## 执行错误、安全性与良好行为

执行错误分为两大类：

-   **捕获错误**（Trapped error）：如除零或非法内存访问，这类错误会使程序立即停止。
-   **未捕获错误**（Untrapped error）：如在缺乏运行时边界检查的情况下访问数组末尾之后的数据，或错误地跳转到内存中的非指令区域，可能导致数据损坏而不立即引发故障。

若不会引起未捕获错误，则程序被认为是**安全的**（Safe）；而**良好行为**（Good behavior）则要求程序避免所有**禁止错误**（Forbidden error），包括**所有未捕获错误**和**部分捕获错误**，类型系统利用**静态检查**（Static checking）和必要的**动态检查**（Dynamic checking）来确保这一点。

一个具有良好行为的程序必然是安全的，所有程序代码都具有良好行为的语言称为**强制检查语言**（Stringly checked language），应至少满足以下条件：

-   不会发生任何未捕获错误
-   不会发生任何被视为禁止错误的捕获错误
-   其它捕获错误可能会发生，这部分由程序员负责

## 有类型与无类型语言

**有类型语言**（Typed language）通过给程序变量规定明确的取值范围来避免错误。如一个类型为 Boolean 的变量 $x$ 在每次运行时只能取布尔值，使得表达式 $not(x)$ 始终有明确意义。而**无类型语言**（Untyped language）不限制变量的取值，或视所有值为单一通用类型（Universal type），这可能导致操作被应用于不适当的参数，从而产生任意结果、故障或异常。一个极端例子是纯 λ 演算（Pure λ-calculus），所有值都是函数，唯一的操作（函数应用）永远不会失败。

有类型语言可以通过在编译时进行静态检查从而强制程序具有良好行为，称为**静态检查语言**（Static checking language）。这种检查过程称为**类型检查**（Typechecking），而执行这一检查的算法称为**类型检查器**（Typechecker）。通过类型检查器检查的程序称为**类型良好**（Well-typed）的。

无类型语言则可以通过执行足够详细的动态检查来排除所有禁止错误，从而实现良好行为。如检查所有数组边界以及所有除法操作，在可能发生禁止错误时生成可恢复的异常。如 Lisp 没有静态检查也没有类型系统，但仍然是强制检查的。

即使是静态检查语言通常也需要在运行时进行测试以保证安全性，如检查数组边界。一个语言是静态检查的并不意味着程序没有动态检查。

有类型语言可能是**显式标注类型**（Explicitly typed）的，也可能依靠类型推断实现**隐式类型**（Implicitly typed），如 ML 和 Haskell。

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250213223742605.png" alt="Table 1. Safety" style="zoom:50%;" />

## 安全性与语言设计的权衡

一个具有良好行为的程序必然是安全的。类型系统的主要目标是通过排除所有未捕获错误来确保语言安全。不过大多数类型系统通常会确保良好行为从而隐含地保证类型安全。

静态检查语言并不保证绝对安全，因为一些语言的禁止错误集合不包括所有的未捕获错误，称为**弱检查**（Weakly checked）。

安全性通常需要在性能上付出代价，因为实现安全性往往依赖于运行时检查，而这些检查可能带来额外开销。

-   C 语言因追求高性能而刻意设计为不安全，但其广泛应用和随之而来的安全漏洞（如由于指针算术和缺乏数组边界检查导致的缓冲区溢出）促使开发安全子集以及引入额外的运行时检查。
-   安全性带来的故障停止、调试便利、运行时结构的完整性（支持垃圾回收）以及系统安全（如操作系统内核和网页浏览器加载外部代码）等优势，在整体上降低了开发和维护成本。

## 类型系统的工程优势

类型系统不仅有助于防止错误，还带来许多工程上的好处：

-   **执行效率**：准确的类型信息可消除对指针解引用时的空检查，避免运行时检查开销
-   **开发效率**：类型检查能在编译时捕捉大部分常见错误，使调试过程更简单
-   **编译与模块化**：类型信息构成模块接口，使各模块可以独立编译，从而提高编译效率和可维护性
-   **大规模协作**：明确的类型接口降低了各模块间的依赖，便于团队协作和局部代码重构
-   **安全保障**：防止诸如将整数随意转换为指针类型等危险操作，避免可能的安全漏洞

## 类型系统的基本属性与形式化方法

类型系统应具备以下特性：

-   **可判定性**（Decidably verifiable）：存在类型检查算法，能在编译时确定程序是否符合类型要求
-   **透明性**（Transparent）：能够直观预见程序是否能通过类型检查，且错误原因应明确
-   **可执行性**（Enforceable）：类型声明应尽可能在静态阶段得到验证，必要时辅以动态检查，保证声明与程序行为的一致

形式化类型系统通常包括以下步骤：

1.  **描述语法**（Syntax）：定义类型和项（Term）的结构
2.  **确定作用域规则**（Scoping rule）：通常采用静态作用域，将标识符与其声明位置严格对应。而缺乏静态作用域则称为动态作用域
3.  **建立类型规则**（Type rule）：描述项 $M$ 与 类型 $A$ 之间的关系。如 has-type 关系 $M : A$、子类型关系 $A <: B$，以及类型等价关系 $A = B$
4.  **引入静态类型环境**（Static typing environment）：记录程序中自由变量的类型，对应于编译器在类型检查阶段使用的符号表。如 has-type 关系 $M : A$ 通常写作为 $\Gamma\vdash M : A$，表示在环境 $\Gamma$ 下，$M$ 的类型为 $A$
5.  **定义语义**（Semantics）：确保程序项与其运行结果在类型上保持一致

## 类型等价问题

**类型等价**（Type equivalence）问题的关键在于确定何时不同书写的类型表达式可以视为等同。如下面的例子展示了两种可能的解释：

```
type X = Bool
type Y = Bool
```

-   若仅依据 X 和 Y 所关联的类型判断，则属于**结构性等价**（Structural equivalence）
-   若依据类型名称的不同而区分，则属于**按名称等价**（By-name equivalence）

实际语言中常采用两者的混合策略。结构性等价在数据存储和网络传输中具有明显优势，而按名称等价在处理独立开发或编译的代码时也有其独特作用。

# 2 语言的类型系统

## 类型系统的基本概念

### 独立性

类型系统规定了编程语言中的类型规则，与具体的类型检查算法相互独立，类似于用形式文法（Formal grammar）描述语法而不涉及具体解析算法。

### 分离职责

-   类型系统属于语言定义的一部分
-   类型检查算法属于编译器的实现

这种分离使得描述和理解语言的类型特性更加简单，同时允许不同编译器使用不同的算法来实现相同的类型系统。

### 效率考量

尽管可以设计出只支持不可行或不存在算法的类型系统，但通常目标是支持高效的类型检查算法。

## 判断

### 基本形式

**判断**（Judgments）是由上下文和断言组成的形式化陈述，通常写作：
$$
\Gamma\vdash\mathfrak{J}
$$
其中：

-   $\Gamma$ 是**静态类型环境**（Static typing environment），如 $\empty, x_1 : A_1, x_2:A_2, \cdots, x_n:A_n$
-   **空环境**记作 $\empty$，环境中声明的变量集合记作 $dom(\Gamma)$
-   $\mathfrak{J}$ 表示具体的断言，其所有自由变量均在 $\Gamma$ 中声明

### 类型判断

最核心的判断形式是类型判断，记作
$$
\Gamma\vdash M:A
$$
表示在环境 $\Gamma$ 下，项 $M$ 的类型为 $A$。如：

-   $true$ 的类型为 $Bool$，记作 $\empty\vdash true : Bool$
-   $x+1$ 的类型为 $Nat$，前提是 $x$ 的类型为 $Nat$，记作 $\empty, x : Nat\vdash x+1 : Nat$

一个常见的判断是断言一个环境是**良构的**（Well-formed），即已被正确构造：
$$
\Gamma\vdash\diamond
$$

## 类型规则

类型规则通常以如下形式给出：

-   上方列出若干前提判断 $\Gamma_i\vdash\mathfrak{J}_i$ （前提数目可为零）
-   下方写出结论判断 $\Gamma\vdash\mathfrak{J}$
-   每条规则都有名称

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/202502020212846.png" alt="类型规则" style="zoom:60%;" />

### 规则的作用

类型规则用以从已知有效的判断推出新的判断，通过这样的链式推理构造出整个推导树。

-   数字规则：规定在任一良构环境 $\Gamma\vdash\diamond$ 下，任何数字都是 $Nat$ 类型的表达式

-   加法规则：规定若 $M$ 和 $N$ 均表示自然数，则 $M+N$ 表示自然数，且环境 $\Gamma$ 对 $M$、$N$ 和 $M+N$ 一致传递

    <img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/202502020217876.png" alt="数字规则/加法规则" style="zoom:60%;" />

-   空环境规则： 规定空环境没有前提判断，且是良构的
    $$
    (Env\ \empty) \\\\
    \frac{}{\empty\vdash\diamond}
    $$
    

类似上述的一组类型规则就可构成一个形式类型系统。

## 类型推导

**推导**（Derivation）是一棵由判断构成的树：叶子在顶部、根在底部，每个判断均由其直接上方的判断通过某条类型规则得到。一个判断若能作为推导树的根节点获得，则称其为**有效判断**，代表能通过正确应用类型规则得到。

通过已有规则可构造如下推导，如：

![推导树](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/202502031734530.png)

是一个有效判断，每一步的结论旁标注了所用规则。

## 良好类型化与类型推断

### 良好类型化定义

在环境 $\Gamma$ 下，若存在某类型 $A$ 使得：
$$
\Gamma\vdash M:A
$$


成立，则称项 $M$ 为**良好类型化**（Well-typed）。

### 类型推断问题

指为某项发现一个推导从而确定其类型的过程。如在规则 Env $\empty$、Val $n$ 和 Val $+$ 构成的系统中，可以在空环境下为 $1+2$ 推断出类型 $Nat$。

### 类型系统对类型推断的影响

添加规则 $\Gamma\vdash true:Bool$ 后，项 $1+true$ 无法推断出类型，因为没有规则支持自然数与布尔值相加。

若进一步添加规则：

-   前提：$\Gamma\vdash M:Nat$ 和 $\Gamma\vdash N:Bool$
-   结论：$\Gamma\vdash M+N:Nat$（如将 $true$ 解释为 $1$）

则 $1+true$ 可被类型化，这表明类型推断问题对具体类型系统非常敏感，算法实现的难易取决于类型系统的设计。

### 实践中的类型推断

-   对于显式类型化的语言（如 C），类型推断较为容易
-   对于隐式类型化的语言（如 ML）以及涉及多态性（Polymorphism）的情况，类型推断问题更为复杂

## 类型健全性

**类型健全性**（Type soundness）确保良好类型化的程序在执行过程中不会出现运行时错误。

### 与语义的联系

-   **指称语义**（Denotational semantics）：若 $\empty\vdash M : A$ 有效，则应满足 $[M] \in [A]$，即 $M$ 的值属于类型 $A$ 所指称的值集合。
-   **操作语义**（Operational semantics）：若 $\empty\vdash M:A$ 有效，且 $M$ 归约为 $M’$，则有 $\empty\vdash M’: A$

在这两种情况下，类型健全性定理均断言：良好类型化的程序在计算时不会产生执行错误，联系了类型系统与程序语义之间的关系。

# 3 First-order Type Systems

The type systems found in most common procedural languages are called first order. In typetheoretical jargon this means that they lack type parameterization and type abstraction, which are second order features. First-order type systems include (rather confusingly) higher order functions. Pascal and Algol68 have rich first-order type systems, whereas FORTRAN and Algol60 have very poor ones.

A minimal first-order type system can be given for the untyped λ-calculus, where the untyped λ-abstraction λx.M represents a function of parameter x and result M. Typing for this calculus requires only function types and some base types; we will see later how to add other common type structures.

The first-order typed λ-calculus is called system $F_1$. The main change from the untyped λ-calculus is the addition of type annotations for λ-abstractions, using the syntax λx:A.M, where x is the function parameter, A is its type, and M is the body of the function. (In a typed programming language we would likely include the type of the result, but this is not necessary here.) The step from λx.M to λx:A.M is typical of any progression from an untyped to a typed language: bound variables acquire type annotations.

Since $F_1$ is based mainly on function values, the most interesting types are function types: A→B is the type of functions with arguments of type A and results of type B. To get started, though, we also need some basic types over which to build function types. We indicate by Basic a collection of such types, and by $K\in Basic$ any such type. At this point basic types are purely a technical necessity, but shortly we will consider interesting basic types such as Bool and Nat.

The syntax of $F_1$ is given in Table 2. It is important to comment briefly on the role of syntax in typed languages. In the case of the untyped λ-calculus, the context-free syntax describes exactly the legal programs. This is not the case in typed calculi, since good behavior is not (usually) a context-free property. The task of describing the legal programs is taken over by the type system. For example, λx:K.x(y) respects the syntax of $F_1$ given in Table 2, but is not a program of $F_1$ because it is not well typed, since K is not a function type. The context-free syntax is still needed, but only in order to define the notions of free and bound variables; that is, to define the scoping rules of the language. Based on the scoping rules, terms that differ only in their bound variables, such as λx:K.x and λy:K.y, are considered syntactically identical. This convenient identification is implicitly assumed in the type rules (one may have to rename bound variables in order to apply certain type rules).

![Table 2. Syntax of F1](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/202502031752304.png)

The definition of free variables for $F_1$ is the same as for the untyped λ-calculus, simply ignoring the typing annotations.

We need only three simple judgments for $F_1$; they are shown in Table 3. The judgment $\Gamma\vdash A$ is in a sense redundant, since all syntactically correct types A are automatically well formed in any environment $\Gamma$. In second order systems, however, the well formedness of types is not captured by grammar alone, and the judgement $\Gamma\vdash A$ becomes essential. It is convenient to adopt this judgment now, so that later extensions are easier.

![Table 3. Judgments for F1](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212182621524.png)

Validity for these judgments is defined by the rules in Table 4. The rule (Env $\empty$) is the only one that does not require assumptions (i.e., it is the only axiom). It states that the empty environment is a valid environment. The rule (Env $x$) is used to extend an environment $\Gamma$ to a longer environment $\Gamma, x:A$, provided that A is a valid type in $\Gamma$. Note that the assumption $\Gamma\vdash A$ implies, inductively, that $\Gamma$ is valid. That is, in the process of deriving $\Gamma\vdash A$ we must have derived $\Gamma\vdash\diamond$. Another requirement of this rule is that the variable $x$ must not be defined in $\Gamma$. We are careful to keep variables distinct in environments, so that when $\Gamma, x:A \vdash M : B$ has been derived, as in the assumption of (Val Fun), we know that x cannot occur in $dom(\Gamma)$.

![Table 4. Rules for F1](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212183319096.png)

The rules (Type Const) and (Type Arrow) construct types. The rule (Val $x$) extracts an assumption from an environment: we use the notation $\Gamma', x:A, \Gamma"$, rather informally, to indicate that $x:A$ occurs somewhere in the environment. The rule (Val Fun) gives the type $A\rightarrow B$ to a function, provided that the function body receives the type $B$ under the assumption that the formal parameter has type A. Note how the environment changes length in this rule. The rule (Val Appl) applies a function to an argument: the same type $A$ must appear twice when verifying the premises.

Table 5 shows a rather large derivation where all of the rules of $F_1$ are used.

![Table 5. A derivation in F1](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212183803328.png)

Now that we have examined the basic structure of a simple first-order type system, we can begin enriching it to bring it closer to the type structure of actual programming languages. We are going to add a set of rules for each new type construction, following a fairly regular pattern. We begin with some basic data types: the type $Unit$, whose only value is the constant $unit$; the type $Bool$, whose values are $true$ and $false$; and the type $Nat$, whose values are the natural numbers.

The $Unit$ type is often used as a filler for uninteresting arguments and results; it is called $Void$ or $Null$ in some languages. There are no operations on $Unit$, so we need only a rule stating that $Unit$ is a legal type, and one stating that unit is a legal value of type $Unit$ (Table 6).

![Table 6. Unit Type](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212184114773.png)

We have a similar pattern of rules for $Bool$, but booleans also have a useful operation, the conditional, that has its own typing rule (Table 7). In the rule (Val Cond) the two branches of the conditional must have the same type A, because either may produce the result.

The rule (Val Cond) illustrates a subtle issue about the amount of type information needed for typechecking. When encountering a conditional expression, a typechecker has to infer separately the types of $N_1$ and $N_2$, and then find a single type $A$ that is compatible with both. In some type systems it might not be easy or possible to determine this single type from the types of $N_1$ and $N_2$. To account for this potential typechecking difficulty, we use a subscripted type to express additional type information: $if_A$ is a hint to the typechecker that the result type should be $A$, and that types inferred for $N_1$ and $N_2$ should be separately compared with the given $A$. In general, we use subscripted types to indicate information that may be useful or necessary for typechecking, depending on the whole type system under consideration. It is often the task of a typechecker to synthesize this additional information. When it is possible to do so, subscripts may be omitted. (Most common languages do not require the annotation $if_A$.)

![Table 7. Bool Type](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212184425363.png)

The type of natural numbers, $Nat$ (Table 8), has $0$ and $succ$ (successor) as generators. Alternatively, as we did earlier, a single rule could state that all numeric constants have type $Nat$. Computations on $Nat$ are made possible by the $pred$ (predecessor) and $isZero$ (test for zero) primitives; other sets of primitives can be chosen.

![Table 8. Nat Type](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212184558667.png)

Now that we have a collection of basic types, we can begin looking at structured types, starting with product types (Table 9). A product type $A_1\times A_2$ is the type of pairs of values with first component of type $A_1$ and second component of type $A_2$. These components can be extracted with the projections $first$ and $second$, respectively. Instead of (or in addition to) the projections, one can use a $with$ statement that decomposes a pair $M$ and binds its components to two separate variables $x_1$ and $x_2$ in the scope $N$. The $with$ notation is related to pattern matching in ML, but also to Pascal’s with; the connection with the latter will become clearer when we consider record types.

Product types can be easily generalized to tuple types $A_1\times\cdots\times A_n$, with corresponding generalized projections and generalized $with$.

![Table 9. Product Types](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212185255193.png)

Union types (Table 10) are often overlooked, but are just as important as product types for expressiveness. An element of a union type $A_1+A_2$ can be thought of as an element of $A_1$ tagged with a $left$ token (created by $inLeft$), or an element of $A_2$ tagged with a $right$ token (created by $inRight$). The tags can be tested by $isLeft$ and $isRight$, and the corresponding value extracted with $asLeft$ and $asRight$. If $asLeft$ is mistakenly applied to a right-tagged value, a trapped error or exception is produced; this trapped error is not considered a forbidden error. Note that it is safe to assume that any result of $asLeft$ has type $A_1$, because either the argument is left tagged, in which case the result is indeed of type $A_1$, or it is right tagged, in which case there is no result. Subscripts are used to disambiguate some of the rules, as we discussed in the case of the conditional.

The rule (Val Case) describes an elegant construct that can replace $isLeft$, $isRight$, $asLeft$, $asRight$, and the related trapped errors. (It also eliminates any dependence of union operations on the $Bool$ type). The $case$ construct executes one of two branches depending on the tag of $M$, with the untagged contents of $M$ bound to $x_1$ or $x_2$ in the scope of $N_1$ or $N_2$, respectively. A vertical bar separates the branches.

![Table 10. Union Types](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212185810926.png)

In terms of expressiveness (if not of implementation) note that the type $Bool$ can be defined as $Unit + Unit$, in which case the $case$ construct reduces to the conditional. The type $Int$ can be defined as $Nat + Nat$, with one copy of $Nat$ for the nonnegative integers and the other for the negative ones. We can define a prototypical trapped error as $error_A = asRight(inLeft_A(unit)) : A$. Thus, we can build an error expression for each type.

Product types and union types can be iterated to produce tuple types and multiple unions. However, these derived types are rather inconvenient, and are rarely seen in languages. Instead, $labeled$ products and unions are used: they go under the names of record types and variant types, respectively.

A record type is the familiar named collection of types, with a value-level operation for extracting components by name. The rules in Table 11 assume the syntactic identification of record types and records up to reordering of their labeled components; this is analogous to the syntactic identification of functions up to renaming of bound variables.

The $with$ statement of product types is generalized to record types in (Val Record With). The components of the record $M$ labeled $l_1, \cdots, l_n$ are bound to the variables $x_1, \cdots, x_n$ in the scope of $N$. Pascal has a similar construct, also called $with$, but where the binding variables are left implicit. (This has the rather unfortunate consequence of making scoping depend on typechecking, and of causing hard-to-trace bugs due to hidden variable clashes.)

Product types $A1\times A2$ can be defined as $Record$($first:A_1$, $second:A_2$).

![Table 11. Record Types](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212222635521.png)

Variant types (Table 12) are named disjoint unions of types; they are syntactically identi fied up to reordering of components. The is $l$ construct generalizes $isLeft$ and $isRight$, and the as $l$ construct generalizes $asLeft$ and $asRight$. As with unions, these constructs may be replaced by a $case$ statement, which has now multiple branches.

Union types $A_1+A_2$ can be defined as $Variant$($left:A_1$, $right:A_2$). Enumeration types, such as $\{red, green, blue\}$, can be defined as $Variant$($red:Unit$, $green:Unit$, $blue:Unit$).

![Table 12. Variant Types](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212222643726.png)

Reference types (Table 13) can be used as the fundamental type of mutable locations in imperative languages. An element of $Ref(A)$ is a mutable cell containing an element of type $A$. A new cell can be allocated by (Val Ref), updated by (Val Assign), and explicitly dereferenced by (Val Deref). Since the main purpose of an assignment is to perform a side effect, its resulting value is chosen to be unit.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212223039934.png" alt="Table 13. Reference Types" style="zoom: 67%;" />

Common mutable types can be derived from $Ref$. Mutable record types, for example, can be modeled as record types containing $Ref$ types.

![Table 14. An implementation of arrays](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250212223213572.png)

More interestingly, arrays and array operations can be modeled as in Table 14, where $Array(A)$ is the type of arrays of elements of type $A$ of some length. (The code uses some arithmetic primitives and local let declarations.) The code in Table 14 is of course an inefficient implementation of arrays, but it illustrates a point: the type rules for more complex constructions can be derived from the type rule for simpler constructions. The typing rules for array operations shown in Table 15 can be easily derived from Table 14, according to the rules for products, functions, and refs.

![Table 15. Array Types](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250213222237929.png)

In most programming language, types can be defined recursively. Recursive types are important, since they make all of the other type constructions more useful. They are often introduced implicitly, or without precise explanation, and their characteristics are rather subtle. Hence, their formalization deserves particular care.

The treatment of recursive types requires a rather fundamental addition to $F_1$: environments are extended to include type variables $X$. These type variables are used in recursive types of th form $\mu X.A$ (Table 16), which intuitively denote solutions to recursive equations of the form $X=A$ where $X$ may occur in $A$. The operations $unfold$ and $fold$ are explicit coercions that map between a recursive type $\mu X.A$ and its unfolding $[\mu X.A/X]A$ (where $[B/X]A$ is the substitution of $B$ for all free occurrences of $X$ in $A$), and vice versa. These coercions do not have any run time effect (in the sense that $unfold(fold(M))=M$ and $fold(unfold(M'))=M'$). They are usually omitted from the syntax of practical programming languages, but their existence makes formal treatment easier.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250213222248077.png" alt="Table 16. Recursive Types" style="zoom:67%;" />

A standard application of recursive types is in defining types of lists and trees, in conjunction with products and union types. The type $List_A$ of lists of elements of type $A$ is defined in Table 17, together with the list constructors $nil$ and $cons$, and the list analyzer $listCase$.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250213222400440.png" alt="Table 17. List Types" style="zoom:67%;" />

Recursive types can be used together with record and variant types, to define complex tree structures such as abstract syntax trees. The $case$ and with statements can then be used to analyze these trees conveniently.

When used in conjunction with function types, recursive types are surprisingly expressive. Via clever encodings, one can show that recursion at the value level is already implicit in recursive types: there is no need to introduce recursion as a separate construct. Moreover, in the presence of recursive types, untyped programming can be carried out within typed languages. More precisely, Table 18 shows how to define, for any type $A$, a divergent element $\bot_A$ of that type, and a fixpoint operator $Y_A$ for that type. Table 19 shows how to encode the untyped λ-calculus within typed calculi. (These encoding are for call-by-name; they take slightly different forms in call-by-value.)

![Table 18. Encoding of Divergence and Recursion via Recursive Types](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250213223027682.png)

![Table 19. Encoding the Untyped λ-calculus via Recursive Types](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250213223023871.png)

Type equivalence becomes particularly interesting in the presence of recursive types. We have sidestepped several problems here by not dealing with type definitions, by requiring explici $fold$ $unfold$ coercions between a recursive type and its unfolding, and by not assuming any identifications between recursive types except for renaming of bound variables. In the current formulation we do not need to define a formal judgment for type equivalence: two recursive types are equivalent simply if they are structurally identical (up to renaming of bound variables). This simplified approach can be extended to include type definitions and type equivalence up to unfolding of recursive types. 

# 4 First-order Type Systems for Imperative Languages

Imperative languages have a slightly different style of type systems, mostly because they distinguish commands, which do not produce values, from expressions, which do produce values. (It is quite possible to reduce commands to expressions by giving them type $Unit$, but we prefer to remain faithful to the natural distinction.)

As an example of a type system for an imperative language, we consider the untyped imperative language summarized in Table 20. This language permits us to study type rules for declarations, which we have not considered so far. The treatment of procedures and data types is very rudimentary in this language, but the rules for functions and data described in section 3 can be easily adapted. The meaning of the features of the imperative language should be self-evident.

![Table 20. Syntax of the imperative language](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250213223627583.png)

The judgments for our imperative language are listed in Table 21. The judgments $\Gamma\vdash C$ and $\Gamma\vdash E : A$ correspond to the single judgment $\Gamma\vdash M : A$ of $F_1$, since we now have a distinction between commands $C$ and expressions $E$. The judgment $\Gamma\vdash D \therefore S$ assigns a signature $S$ to a declaration $D$; a signature is essentially the type of a declaration. In this simple language a signature consists of a single component, for example $x : Nat$, and a matching declaration could be var $x : Nat = 3$. In general, signatures would consist of lists of such components, and would look very similar or identical to environments $\Gamma$.

![Table 21. Judgments for the imperative language](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250213224315408.png)

Table 22 lists the type rules for the imperative language.

![Table 22. Type rules for the imperative language](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250213224551267.png)

The rules (Env ...), (Type ...), and (Expr ...) are straightforward variations on the rules we have seen for $F_1$. The rules (Decl ...) handle the typing of declarations. The rules (Comm ...) handle commands; notice how (Comm Block) converts a signature to a piece of an environment when checking the body of a block.

# 5 Second-order Type Systems

Many modern languages include constructs for type parameters, type abstraction, or both. Type parameters can be found in the module system of several languages, where a generic module, class, or interface is parameterized by a type to be supplied later. Planned extensions of Java and C# use type parameters at the class and interface level. (C++ templates are similar to type parameters, bur are actually a form of macro-expansion, with very different properties.) Polymorphic languages such as ML and Haskell use type parameters more pervasively, at the function level. Type abstraction can be found in conjunction with modules, in the form of opaque types in interfaces, as in Modula-2 and Modula-3. Languages such as CLU use type abstraction at the data level, to obtain abstract data types. These advanced features can be modeled by so-called second-order type systems.

Second-order type systems extend first-order type systems with the notion of $type\ parameters$. A new kind of term, written $\lambda X.M$, indicates a program $M$ that is parameterized with respect to a type variable $X$ that stands for an arbitrary type. For example, the identity function for a fixed type $A$, written $\lambda x:A.x$, can be turned into a parametric identity function by abstracting over $A$ and writing $id \overset{\triangle}{=} \lambda X.\lambda x:X.x$. One can then instantiate such a parametric function to any given type $A$ by a type instantiation, written $id\ A$, which produces back $\lambda x:A.x$. 

Corresponding to the new terms $\lambda X.M$ we need new $universally\ quantified$ types. The type of a term such as $\lambda X.M$ is written $\forall X.A$, meaning that forall $X$, the body $M$ has type $A$ (here $M$ and $A$ may contain occurrences of $X$). For example, the type of the parametric identity is $id : \forall X.X\rightarrow X$, since forall $X$, the type instantiation $id\ X$ has type $X\rightarrow X$.

The pure second-order system $F_2$ (Table 23) is based exclusively on type variables, function types, and quantified types. Note that we are dropping the basic types $K$, since we can now use type variables as the basic case. It turns out that virtually any basic type of interest can be encoded within $F_2$. Similarly, product types, sum types, existential types, and some recursive types, can be encoded within $F_2$: polymorphism has an amazing expressive power. Thus there is little need, technically, to deal with these type constructions directly.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214194606242.png" alt="Table 23. Syntax of F2" style="zoom: 60%;" />

Free variables for $F_2$ types and terms can be defined in the usual fashion; suffice it to say that $\forall X.A$ binds $X$ in $A$ and $\lambda X.M$ binds $X$ in $M$. An interesting aspect of $F_2$ is the substitution of a type for a type variable that is carried out in the type rule for type instantiation, (Val Appl2).

![Table 24. Judgments for F2](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214194739730.png)

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214194852507.png" alt="Table 25. Rules for F2" style="zoom: 60%;" />

The judgments for $F_2$ (Table 24) are the same ones as for $F_1$, but the environments are richer. With respect to $F_1$, the new rules (Table 25), are: (Env X), which adds a type variable to the environment; (Type Forall), which constructs a quantified type $\forall X.A$ from a type variable $X$ and a type $A$ where $X$ may occur; (Val Fun2), which builds a polymorphic abstraction; and (Val Appl2), which instantiates a polymorphic abstraction to a given type, where $[B/X]A$ is the substitution of $B$ for all the free occurrences of $X$ in $A$. For example, if $id$ has type $\forall X.X\rightarrow X$ and $A$ is a type, then by (Val Appl2) we have that $id\ A$ has type $[A/X](X\rightarrow X)\equiv A\rightarrow A$. As a simple but instructive exercise, the reader may want to build the derivation for $id(\forall X.X\rightarrow X)(id)$.

As extensions of $F_2$ we could adopt all the first-order constructions that we already discussed for $F_1$. A more interesting extension to consider is $existentially\ quantified$ types, also known as type abstractions:

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214195543697.png" alt="Table 26. Existential types" style="zoom:67%;" />
To illustrate the use of existentials, we consider an abstract type for booleans. As we said earlier, booleans can be represented as the type $Unit+Unit$. We can now show how to hide this representation detail from a client who does not care how booleans are implemented, but who wants to make use of $true$, $false$ and $cond$ (conditional). We first define an interface for such a client to use,

![BoolInterface](https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214195952333.png)

This interface declares that there exists a type $Bool$ (without revealing its identity) that supports the operations $true$, $false$ and $cond$ of appropriate types. The conditional is parameterized with respect to its result type $Y$, which may vary depending of the context of usage.

Next we define a particular implementation of this interface; one that represents $Bool$ as $Unit+Unit$, and that implements the conditional via a case statement. The boolean representation type and the related boolean operations are packaged together by the pack construct.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214200143379.png" alt="boolModule" style="zoom:67%;" />

Finally, a client could make use of this module by opening it, and thus getting access to an abstract name $Bool$ for the boolean type, and a name $boolOp$ for the record of boolean operations. These names are used in the next example for a simple computation that returns a natural number. (The computation following $in$ is, essentially, if $boolOp.true$ then 1 else 0.)

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214200631366.png" alt="open_nat boolModule" style="zoom:67%;" />

The reader should verify that these examples typecheck according to the rules previously given. Note the critical third assumption of (Val Open), which implies that the result type $B$ cannot contain the variable $X$. That assumption forbids writing, for example, $boolOp.true$ as the body of $open$ (following $in$) in the previous example, since the result type would then be the variable $Bool$. Because of that third assumption, the abstract name of the representation type ($Bool$) cannot escape the scope of $open$, and therefore values having the representation type cannot escape either. A restriction of this kind is necessary, otherwise the representation type might become known to clients.

# 6 Subtyping

Typed object-oriented languages have particularly interesting and complex type systems. There is little consensus about what characterizes these languages, but at least one feature is almost universally present: subtyping. Subtyping captures the intuitive notion of inclusion between types, where types are seen as collections of values. An element of a type can be considered also as an element of any of its supertypes, thus allowing a value (object) to be used flexibly in many different typed contexts.

When considering a subtyping relation, such as the one found in object-oriented programming languages, it is customary to add a new judgment $\Gamma\vdash A <: B$ stating that $A$ is a subtype of $B$ (Table 27). The intuition is that any element of $A$ is an element of $B$ or, more appropriately, any program of type $A$ is also a program of type $B$.

One of the simplest type systems with subtyping is an extension of $F_1$ called $F_{1<:}$. The syntax of $F_1$ is unchanged, except for the addition of a type $Top$ that is a supertype of all types. The existing type rules are also unchanged. The subtyping judgment is independently axiomatized, and a single type rule, called subsumption, is added to connect the typing judgment to the subtyping judgment. 

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214201319026.png" alt="Table 27. Judgments for type systems with subtyping" style="zoom:60%;" />

The subsumption rule states that if a term has type $A$, and $A$ is a subtype of $B$, then the term also has type $B$. That is, subtyping behaves very much like set inclusion, when type membership is seen as set membership.

The subtyping relation in Table 28 is defined as a reflexive and transitive relation with a maximal element called $Top$, which is therefore interpreted as the type of all well typed terms. 

The subtype relation for function types says that $A\rightarrow B$ is a subtype of $A'\rightarrow B'$ if $A'$ is a subtype of $A$, and $B$ is a subtype of $B'$. Note that the inclusion is inverted (contravariant) for function arguments, while it goes in the same direction (covariant) for function results. Simpleminded reasoning reveals that this is the only sensible rule. A function $M$ of type $A\rightarrow B$ accepts elements of type $A$; obviously it also accepts elements of any subtype $A'$ of $A$. The same function $M$ returns elements of type $B$; obviously it returns elements that belong to any supertype $B'$ of $B$. Therefore, any function $M$ of type $A\rightarrow B$, by virtue of accepting arguments of type $A'$ and returning results of type $B'$, has also type $A'\rightarrow B'$. The latter is compatible with saying that $A\rightarrow B$ is a subtype of $A'\rightarrow B'$.

In general, we say that a type variable occurs contravariantly within another type of $F_1$, if it always occurs on the left of an odd number of arrows (double contravariance equals covariance). For example, $X\rightarrow Unit$ and ($Unit\rightarrow X)\rightarrow Unit$ are contravariant in $X$, whereas $Unit\rightarrow X$ and $(X\rightarrow Unit)\rightarrow X$ are covariant in $X$.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214202424285.png" alt="Table 28. Additional rules for F1 Subtyping" style="zoom:67%;" />

Ad hoc subtyping rules can be added on basic types, such as $Nat <: Int$.

All of the structured types we considered as extensions of $F_1$ admit simple subtyping rules; therefore, these structured types can be added to $F_{1<:}$ as well (Table 29). Typically, we need to add a single subtyping rule for each type constructor, taking care that the subtyping rule is sound in conjunction with subsumption. The subtyping rules for products and unions work component-wise. The subtyping rules for records and variants operate also lengthwise: a longer record type is a subtype of a shorter record type (additional fields can be forgotten by subtyping), whereas a shorter variant type is a subtype of a longer variant type (additional cases can be introduced by subtyping). For example,

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214202817499.png" alt="WorkingAge" style="zoom:60%;" />

Then,

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214202854784.png" alt="WorkingAge" style="zoom:60%;" />

Reference types do not have any subtyping rule: $Ref(A) <: Ref(B)$ holds only if $A=B$ (in which case $Ref(A) <: Ref(B)$ follows from reflexivity). This strict rule is necessary because references can be both read and written, and hence behave both covariantly and contravariantly. For the same reason, array types have no additional subtyping rules.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214203314467.png" alt="Table 29. Additional rules for extensions of F1 Subtyping" style="zoom:67%;" />

As was the case for $F_1$, a change to the structure of environments is necessary when considering recursive types. This time, we must add bounded variables to environments (Table 30). Variables bound by $Top$ correspond to our old unconstrained variables. The soundness of the subtyping rule (Sub Rec) for recursive types (Table 31) is not obvious, but the intuition is fairly straightforward. To check whether $\mu X.A <: \mu Y.B$ we assume $X<:Y$ and we check $A <: B$; the assumption helps us when finding matching occurrences of $X$ and $Y$ in $A$ and $B$, as long as they are in covariant contexts. A simpler rule asserts that $\mu X.A <: \mu X.B$ whenever $A <: B$ for any $X$, but this rule is unsound when $X$ occurs in contravariant contexts (e.g., immediately on the left of an arrow).

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214203849006.png" alt="Table 30. Environments with bounded variables" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214203924984.png" alt="Table 31. Subtyping recursive types" style="zoom:67%;" />

The bounded variables in environments are also the basis for the extension of $F_2$ with subtyping, which gives a system called $F_{2<:}$ (Table 32). In this system the term $\lambda X<:A.M$ indicates a program $M$ parameterized with respect to a type variable $X$ that stands for an arbitrary subtype of $A$. This is a generalization of $F_2$, since the $F_2$ term $\lambda X.M$ can be represented as $\lambda X<:Top.M$. Corresponding to the terms $\lambda X<:A.M$, we have bounded type quantifiers of the form $\forall X<:A.B$.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214205627386.png" alt="Table 32. Syntax of F2 Subtyping" style="zoom: 60%;" />

Scoping for $F_{2<:}$ types and terms is defined similarly to $F_2$, except that $\forall X<:A.B$ binds $X$ in $B$ but not in $A$, and $\lambda X<:A.M$ binds $X$ in $M$ but not in $A$. 

The type rules for $F_{2<:}$ consist of most of the type rules for $F_{1<:}$ (namely, (Env $\empty$), (Env $x$), (Type Top), (Type Arrow), (Sub Refl), (Sub Trans), (Sub Top), (Sub Arrow), (Val Subsumption), (Val $x$), (Val Fun), and (Val Appl)), plus the rules for bounded variables (namely, (Env $X<:$), (Type $X<:$), and (Sub $X<:$)), and the ones listed in Table 33 for bounded polymorphism.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214210102746.png" alt="Table 33. Rules for bounded universal quantifiers" style="zoom:67%;" />

As for $F_2$, we do not need to add other type constructions to $F_{2<:}$, since all of the common ones can be expressed within it (except for recursion). Moreover, it turns out that the encodings used for $F_2$ satisfy the expected subtyping rules. For example, it is possible to encode bounded existential types so that the rules described in Table 34 are satisfied. The type $\exist X<:A.B$ represent a partially abstract type, whose representation type $X$ is not completely known, but is known to be a subtype of $A$. This kind of partial abstraction occurs in some languages based on subtyping (e.g., in Modula-3).

Some nontrivial work is needed to obtain encodings of record and variant types in $F_{2<:}$ that satisfy the expected subtyping rules, but even those can be found.

# 7 Equivalence

For simplicity, we have avoided describing certain judgments that are necessary when type systems become complex and when one wishes to capture the semantics of programs in addition to their typing. We briefly discuss some of these judgments.

A type equivalence judgment, of the form $\Gamma\vdash A = B$, can be used when type equivalence is nontrivial and requires precise description. For example, some type systems identify a recursive type and its unfolding, in which case we would have $\Gamma\vdash\mu X.A = [\mu X.A/X]A$ whenever $\Gamma\vdash\mu X.A$.

As another example, type systems with type operators $\lambda X.A$ (functions from types to types) have a reduction rule for operator application of the form $\Gamma\vdash  (\lambda X.A) B = [A/X]B$. The type equivalence judgment is usually employed in a retyping rule stating that if $\Gamma\vdash M : A$ and $\Gamma\vdash A = B$ then $\Gamma\vdash M : B$.

A term equivalence judgment determines which programs are equivalent with respect to a common type. It has the form $\Gamma\vdash M = N : A$. For example, with appropriate rules we could determine that $\Gamma\vdash 2+1 = 3 : Int$. The term equivalence judgment can be used to give a typed semantics to programs: if $N$ is an irreducible expression, then we can consider N as the resulting value of the program $M$.

# 8 Type inference

Type inference is the problem of finding a type for a term within a given type system, if any type exists. In the type systems we have considered earlier, programs have abundant type annotations Thus, the type inference problem often amounts to little more than checking the mutual consistency of the annotations. The problem is not always trivial but, as in the case of $F_1$, simple typechecking algorithms may exist.

A harder problem, called typability or type reconstruction, consists in starting with an untyped program $M$, and finding an environment $\Gamma$, a type-annotated version $M'$ of $M$, and a type $A$ such that $A$ is a type for $M'$ with respect to $\Gamma$. (A type-annotated program $M'$ is simply one that stripped of all type annotations reduces back to $M$.) The type reconstruction problem for the untyped λ-calculus is solvable within $F_1$ by the Hindley-Milner algorithm used in ML; in addition, that algorithm has the property of producing a unique representation of all possible $F_1$ typings of a λ-term. The type reconstruction problem for the untyped λ-calculus, however, is not solvable within $F_2$. Type reconstruction within systems with subtyping is still largely an open problem, although special solutions are beginning to emerge.

We concentrate here on the type inference algorithms for some representative systems: $F_1$, $F_2$, and $F_{2<:}$. The first two systems have the unique type property: if a term has a type it has only one type. In $F_{2<:}$ there are no unique types, simply because the subsumption rule assigns all of the supertypes of a type to any term that has that type. However, a minimum type property holds: if a term has a collection of types, that collection has a least element in the subtype order. The minimum type property holds for many common extensions of $F_{2<:}$ and of $F_{1<:}$ but may fail in the presence of ad-hoc subtypings on basic types.

## The type inference problem

In a given type system, given an environment $\Gamma$ and a term $M$ is there a type $A$ such that $\Gamma\vdash M: A$ is valid? The following are examples:

- In $F_1$, given $M\equiv\lambda x:K.x$ and any well-formed $\Gamma$ we have that $\Gamma\vdash M : K\rightarrow K$. 
- In $F_1$, given $M\equiv\lambda\equiv x:K.y(x)$ and $\Gamma\equiv\Gamma', y:K\rightarrow K$ we have that $\Gamma\vdash M : K\rightarrow K$.
- In $F_1$, there is no typing for $\lambda x:B.x(x)$, for any type $B$. 
- However, in $F_{1<:}$ there is the typing $\Gamma\vdash\lambda x:Top\rightarrow B.x(x) : (Top\rightarrow B)\rightarrow B$, for any type $B$, since $x$ can also be given type $Top$.
- Moreover, in $F_1$ with recursive types, there is the typing $\Gamma\vdash\lambda x:B.(unfold_B\ x)(x) : B\rightarrow B$, for $B\equiv\mu X.X\rightarrow X$, since $unfold_B\ x$ has type $B\rightarrow B$.
- Finally, in $F_2$ there is the typing $\Gamma\vdash\lambda x:B. x(B)(x) : B\rightarrow B$, for $B\equiv\forall X.X\rightarrow X$, since $x(B)$ has type $B\rightarrow B$.

(An alternative formulation of the type inference problem requires $\Gamma$ to be found, instead of given. However, in programming practice one is interested only in type inference for programs embedded in a complete programming context, where $\Gamma$ is therefore given.)

We begin with the type inference algorithm for pure $F_1$, given in Table 35. The algorithm can be extended in straightforward ways to all of the first-order type structures studied earlier. This is the basis of the typechecking algorithms used in Pascal and all similar procedural languages.

The main routine $Type(\Gamma, M)$, takes an environment $\Gamma$ and a term $M$ and produces the unique type of $M$, if any. The instruction $fail$ causes a global failure of the algorithm: it indicates a typing error. In this algorithm, as in the ones that follow, we assume that the initial environ ment parameter $\Gamma$ is well formed so as to rule out the possibility of feeding invalid environments to internal calls. (For example, we may start with the empty environment when checking a full program.) In any case, it is easy to write a subroutine that checks the well formedness of an environment, from the code we provide. The case for $\lambda x:A.M$ should have a restriction requiring that $x\notin dom(\Gamma)$, since $x$ is used to extend $\Gamma$. However, this restriction can be easily sidestepped by renaming, e.g., by making all binders unique before running the algorithm. We omit this kind of restrictions from Tables 35, 36, and 37.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214213949909.png" alt="Table 35. Type inference algorithm for F1" style="zoom:60%;" />

As an example, let us consider the type inference problem for term $\lambda z:K.y(z)$ in the environment $\empty, y:K\rightarrow K$, for which we gave a full $F_1$ derivation in section 3. The algorithm proceeds as follows:

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214214131314.png" alt="Type inference" style="zoom:60%;" />

The type inference algorithm for $F_2$ (Table 36) is not much harder than the one for $F_1$, but it requires a subroutine $Good(\Gamma, A)$ to verify that the types encountered in the source program are well formed. This check is necessary because types in $F_2$ contain type variables that might be unbound. A substitution subroutine must also be used in the type instantiation case, $M\ A$.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214214344019.png" alt="Table 36. Type inference algorithm for F2" style="zoom:60%;" />

The type inference algorithm for $F_{2<:}$, given in Table 37, is more subtle. The subroutine $Subtype(\Gamma, A, B)$ attempts to decide whether $A$ is a subtype of $B$ in $\Gamma$, and is at first sight straight-forward. It has been shown, though, that Subtype is only a semialgorithm: it may diverge on certain pairs $A,B$ that are not in subtype relation. That is, the typechecker for $F_{2<:}$ may diverge on ill typed programs, although it will still converge and produce a minimum type for well typed programs. More generally, there is no decision procedure for subtyping: the type system for $F_{2<:}$ is undecidable. Several attempts have been made to cut $F_{2<:}$ down to a decidable subset; the simplest solution at the moment consists in requiring equal quantifiers bounds in (Sub Forall<:). In any case, the bad pairs $A,B$ are extremely unlikely to arise in practice. The algorithm is still sound in the usual sense: if it finds a type, the program will not go wrong. The only troublesome case is in the subtyping of quantifiers; the restriction of the algorithm to $F_{1<:}$ is decidable and produces minimum types.

<img src="https://raw.githubusercontent.com/genskyff/image-hosting/main/images/20250214214819956.png" alt="Table 37. Type inference algorithm for F2 Subtyping" style="zoom:60%;" />

$F_{2<:}$ provides an interesting example of the anomalies one may encounter in type inference. The type inference algorithm given above is theoretically undecidable but is practically applicable. It is convergent and efficient on virtually all programs one may encounter; it diverges only on some ill typed programs, which should be rejected anyway. Therefore, $F_{2<:}$ sits close to the boundary between acceptable and unacceptable type systems, according to the criteria enunciated in the introduction.

# 9 Summary and Research Issues

## What we learned

Natural questions for a beginner programmer are: What is an error? What is type safety? What is type soundness? (perhaps phrased, respectively, as Which errors will the computer tell me about? Why did my program crash? Why does the computer refuse to run my program?). The answers, even informal ones, are surprisingly intricate. We have paid particular attention to the distinction between type safety and type soundness, and we have reviewed the varieties of static checking, dynamic checking, and absence of checking for program errors in various kinds of languages.

The most important lesson to remember from this chapter is the general framework for formalizing type systems. Understanding type systems, in general terms, is as fundamental as understanding BNF(Backus-Naur Form): it is hard to discuss the typing of programs without the precise language of type systems, just as it is hard to discuss the syntax of programs without the precise language of BNF. In both cases, the existence of a formalism has clear benefits for language design, compiler construction, language learning, and program understanding. We described the formalism of type systems, and how it captures the notions of type soundness and type errors. 

Armed with formal type systems, we embarked on the description of an extensive list of program constructions and of their type rules. Many of these constructions are slightly abstracted versions of familiar features, whereas others apply only to obscure corners of common languages. In both cases, our collection of typing constructions is meant as a key for interpreting the typing features of programming languages. Such an interpretation may be nontrivial, particularly because most language definitions do not come with a type system, but we hope to have provided sufficient background for independent study. Some of the advanced type constructions will appear, we expect, more fully, cleanly, and explicitly in future languages.

In the latter part of the chapter, we reviewed some fundamental type inference algorithms: for simple languages, for polymorphic languages, and for languages with subtyping. These algorithms are very simple and general, but are mostly of an illustrative nature. For a host of pragmatic reasons, type inference for real languages becomes much more complex. It is interesting, though, to be able to describe concisely the core of the type inference problem and some of its solutions.

## Future directions

The formalization of type systems for programming languages, as described in this chapter, evolved as an application of type theory. Type theory is a branch of formal logic. It aims to replace predicate logics and set theory (which are untyped) with typed logics, as a foundation for mathematics.

One of the motivations for these logical type theories, and one of their more exciting applications, is in the mechanization of mathematics via proof checkers and theorem provers. Typing is useful in theorem provers for exactly the same reasons it is useful in programming. The mechanization of proofs reveals striking similarities between proofs and programs: the structuring problems found in proof construction are analogous to the ones found in program construction. Many of the arguments that demonstrate the need for typed programming languages also demonstrate the need for typed logics.

Comparisons between the type structures developed in type theory and in programming are, thus, very instructive. Function types, product types, (disjoint) union types, and quantified types occur in both disciplines, with similar intents. This is in contrast, for example, to structure used in set theory, such as unions and intersections of sets, and the encoding of functions as sets of pairs, that have no correspondence in the type systems of common programming languages.

Beyond the simplest correspondences between type theory and programming, it turns out that the structures developed in type theory are far more expressive than the ones commonly used in programming. Therefore type theory provides a rich environment for future progress in programming languages.

Conversely, the size of systems that programmers build is vastly greater than the size of proofs that mathematicians usually handle. The management of large programs, and in particular the type structures needed to manage large programs, is relevant to the management of mechanical proofs. Certain type theories developed in programming, for example, for object-orientation and for modularization, go beyond the normal practices found in mathematics, and should have something to contribute to the mechanization of proofs.

Therefore, the cross fertilization between logic and programming will continue, within the common area of type theory. At the moment, some advanced constructions used in programming escape proper type-theoretical formalization. This could be happening either because the programming constructions are ill conceived, or because our type theories are not yet sufficiently expressive: only the future will tell. Examples of active research areas are the typing of advanced object-orientation and modularization constructs and the typing of concurrency and distribution.

# Defining Terms

**Abstract type:** A data type whose nature is kept hidden, in such a way that only a predetermined collection of operations can operate on it.

**Contravariant:** A type that varies in the inverse direction from one of its parts with respect to subtyping. The main example is the contravariance of function types in their domain. For example, assume $A<:B$ and vary $X$ from $A$ to $B$ in $X\rightarrow C$; we obtain $A\rightarrow C :> B\rightarrow C$. Thus $X\rightarrow C$ varies in the inverse direction of $X$.

**Covariant:** A type that varies in the same direction as one of its parts with respect to subtyping. For example, assume $A<:B$ and vary $X$ from $A$ to $B$ in $D\rightarrow X$; we obtain $D\rightarrow A <: D\rightarrow B$. Thus $D\rightarrow X$ varies in the same direction as $X$.

**Derivation:** A tree of judgments obtained by applying the rules of a type system.

**Dynamic checking:** A collection of run time tests aimed at detecting and preventing forbidden errors.

**Dynamically checked language:** A language where good behavior is enforced during execution.

**Explicitly typed language:** A typed language where types are part of the syntax.

**First-order type system:** One that does not include quantification over type variables.

**Forbidden error:** The occurrence of one of a predetermined class of execution errors; typically the improper application of an operation to a value, such as $not(3)$.

**Good behavior:** Same as being well behaved.

**Ill typed:** A program fragment that does not comply with the rules of a given type system.

**Implicitly typed language:** A typed language where types are not part of the syntax.

**Judgment:** A formal assertion relating entities such as terms, types, and environments. Type systems prescribe how to produce valid judgments from other valid judgements.

**Polymorphism:** The ability of a program fragment to have multiple types (opposite of monomorphism).

**Safe language:** A language where no untrapped errors can occur.

**Second-order type system:** One that includes quantification over type variables, either universal or existential.

**Static checking:** A collection of compile time tests, mostly consisting of typechecking.

**Statically checked language:** A language where good behavior is determined before execution.

**Strongly checked language:** A language where no forbidden errors can occur at run time (depending on the definition of forbidden error).

**Subsumption:** A fundamental rule of subtyping, asserting that if a term has a type $A$, which is a subtype of a type $B$, then the term also has type $B$.

**Subtyping:** A reflexive and transitive binary relation over types that satisfies subsumption; it asserts the inclusion of collections of values.

**Trapped error:** An execution error that immediately results in a fault.

**Type:** A collection of values. An estimate of the collection of values that a program fragment can assume during program execution.

**Type inference:** The process of finding a type for a program within a given type system.

**Type reconstruction:** The process of finding a type for a program where type information has been omitted, within a given type system.

**Type rule:** A component of a type system. A rule stating the conditions under which a particular program construct will not cause forbidden errors.

**Type safety:** The property stating that programs do not cause untrapped errors.

**Type soundness:** The property stating that programs do not cause forbidden errors.

**Type system:** A collection of type rules for a typed programming language. Same as static type system.

**Typechecker:** The part of a compiler or interpreter that performs typechecking.

**Typechecking:** The process of checking a program before execution to establish its compliance with a given type system and therefore to prevent the occurrence of forbidden errors.

**Typed language:** A language with an associated (static) type system, whether or not types are part of the syntax.

**Typing error:** An error reported by a typechecker to warn against possible execution errors.

**Untrapped error:** An execution error that does not immediately result in a fault.

**Untyped language:** A language that does not have a (static) type system, or whose type system has a single type that contains all values.

**Valid judgment:** A judgment obtained from a derivation in a given type system.

**Weakly checked language:** A language that is statically checked but provides no clear guarantee of absence of execution errors.

**Well behaved:** A program fragment that will not produce forbidden errors at run time.

**Well formed:** Properly constructed according to formal rules.

**Well-typed program:** A program (fragment) that complies with the rules of a given type system.
